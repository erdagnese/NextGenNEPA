---
title: "blast_to_RFDB"
author: "Erin D'Agnese"
date: "10/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This script is used to build a reference DB for COI based off Blast results. 
The goal of this script is to create two files:
1: a fasta file with an identifier/accession number and the representative sequence that has been trimmed to the COI region
2: a text file with the accession/identifier and the taxonomic assignment for the rep sequence in the db

1. Fist step is running this command through the server to blast the results and pull down the data we need for each
```{bash}
#!/bin/bash

BLAST_DB='///_Ev.db'
# BLAST PARAMETERS
PERCENT_IDENTITY="85"
WORD_SIZE="30"
EVALUE="1e-30"
# number of matches recorded in the alignment:
MAXIMUM_MATCHES="50"
CULLING="5"

	################################################################################
	# BLAST CLUSTERS
	################################################################################
	echo $(date +%H:%M) "BLASTing..."
	blast_output="//coi_blast_20210723.txt"
blastn \
		-query "////hash_key.fasta" \
		-db "${BLAST_DB}" \
		-num_threads 4 \
		-perc_identity "${PERCENT_IDENTITY}" \
		-word_size "${WORD_SIZE}" \
		-evalue "${EVALUE}" \
		-max_target_seqs "${MAXIMUM_MATCHES}" \
		-culling_limit="${CULLING}" \
		-outfmt "6 qseqid sseqid sacc pident length mismatch gapopen qcovus qstart qend sstart send evalue bitscore staxids qlen sscinames sseq" \
		-out "${blast_output}"
```

```{r}
library(insect)
library(tidyverse)
library(taxonomizr)
```


2. Using the results from Blast we add headers to the dataframe and convert taxaid to numeric where possible, then find the ones that coerce NAs because they have more than one taxID
```{r}
blast <- read_delim(("/Users/erdag/NextGenNEPA_local/classifiers/COI_build/MiXRun3_format6-1.txt"), col_names = c("qseqid", "sseqid", "sacc", "pident", "length", "mismatch", "gapopen", "qcovus", "qstart", "qend", "sstart", "send", "evalue", "bitscore", "staxid", "qlen", "sscinames", "sseq"), delim = "\t" )

blast %>% mutate (Ntaxid = as.numeric (staxid)) %>% filter(is.na(Ntaxid))
```

There are a number of hashes that have more than 1 taxID which are not being properly handled. To deal with this, we can try a couple things, first could try creating a table of just these ones that we can run separately after making decisions on which TaxID to take. 

```{r}
multi_tax <- blast %>% mutate (Ntaxid = as.numeric (staxid)) %>% filter(is.na(Ntaxid))
#there are 888 entries that have multiple taxIDs per hash
nblast<- blast %>% mutate (taxid = as.numeric (staxid))
```



3.pull the taxonomy using insect 
```{r}
insect::taxonomy() -> worlds.taxonomy
```

4. combine the taxonomy with the blast results
```{r}
blast %>% distinct(staxid) %>%
  pull()-> all.taxids
all.taxids <- map(all.taxids, as.numeric)
insect::get_lineage(all.taxids, worlds.taxonomy) -> all.taxonomy   
```



5. make a dataframe with all the ranks for each taxID
```{r}
Conversion.df <- tibble (taxid = all.taxids,
                         taxonomy = all.taxonomy) %>%
  mutate (Kingdom = map_chr(taxonomy, ~.x["kingdom"]),
          Phylum = map_chr(taxonomy, ~.x["phylum"]),
          Class = map_chr(taxonomy, ~.x["class"]),
          Order = map_chr(taxonomy, ~.x["order"]),
          Family= map_chr(taxonomy, ~.x["family"]),
          Genus = map_chr(taxonomy, ~.x["genus"]),
          Species = map_chr(taxonomy, ~.x["species"]))

Conversion.df %>% filter(is.na(taxid))

```

6. merge the Conversion.df with the blast df to run the consensus script
```{r}
blast.tax <- merge(nblast, Conversion.df, by= "taxid")
```

7. Pull out the accession and taxonomy for the text file
```{r}
ref.txt <- blast.tax %>% select(sacc, Kingdom, Phylum, Class, Order, Family, Genus, Species)
ref.txt <- ref.txt %>% unite(tax, c(Kingdom, Phylum, Class, Order, Family, Genus, Species), sep = ";")
write.table(ref.txt, "/Users/erdag/NextGenNEPA_local/classifiers/COI_build/MiX_test_blastDB.txt", sep="\t", row.names = FALSE, col.names = FALSE, quote = FALSE)
```

8. Pull out the accession and sequence for the fasta
```{r}
ref.fasta <- blast.tax %>% select(sacc, sseq)
names(ref.fasta)[1]<-'name'
names(ref.fasta)[2]<-'seq'

writeFasta<-function(data, filename){
  fastaLines = c()
  for (rowNum in 1:nrow(data)){
    fastaLines = c(fastaLines, as.character(paste(">", data[rowNum,"name"], sep = "")))
    fastaLines = c(fastaLines,as.character(data[rowNum,"seq"]))
  }
  fileConn<-file(filename)
  writeLines(fastaLines, fileConn)
  close(fileConn)
}


writeFasta(ref.fasta, "/Users/erdag/NextGenNEPA_local/classifiers/COI_build/MIX_test_blastRefDB.fasta")

```


9. Create the function to find consensus of the 
```{r}
custom.lca <- function (df, cutoff = 90) {df %>%  # this function allows to change cutoff parameters for a specified dataframe (df)
  group_by(qseqid) %>%
  select( pident, Kingdom, Phylum, Class, Order, Family, Genus, Species) %>%
  nest() %>% # for each query, calculate the agreed taxonomy
  # ungroup %>% slice (1:10) %>%
  mutate(consensus = purrr::map(data,  function(.x) { 
    # If there are 100% matches - keep those and the 90s
    # If not, keep everything
    
    if(max(.x$pident > cutoff )){
      
      .x %>% 
        filter(pident > cutoff) %>% 
        select(-pident) %>% 
        condenseTaxa() %>% # agreement in Phylogeny
      paste(., collapse = ";") # Collapse all the taxa data separatated by ;
      
    }else{
    .x %>% 
        select(-pident) %>% 
    condenseTaxa() %>%
      paste(., collapse = ";")}
  }
                               )) %>%
  select(qseqid, consensus) %>%
  unnest(consensus)} 
```


8.make a dataframe with the consensus for each hash
```{r}
consensus.df <- custom.lca(blast.tax)
```
OKay so that reduced the data set down to just an assignment and the hash, but we need to keep the rest of the data in that and get it into a dataframe with all the ranks next.


```{r}
#make a dataframe with the hashid in one column and the ranks in another column with ";" deliminating them for the txt file for tree building


```

Then need to pull the representative sequences
```{r}
#make a dataframe with the Accession ID, and the hashes from consensus.df, so that we can pull down the sequences from genbank to build a reference
```


```{r}

```

