---
title: "blast_to_RFDB"
author: "Erin D'Agnese"
date: "10/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This script is used to build a reference DB for COI based off Blast results

1. Fist step is running this command through the server to blast the results and pull down the data we need for each
```{bash}
#!/bin/bash

BLAST_DB='/Users/mgb/Documents/APhD/eDNA_extra_docs/MARES/MARES_Ev.db'
# BLAST PARAMETERS
PERCENT_IDENTITY="85"
WORD_SIZE="30"
EVALUE="1e-30"
# number of matches recorded in the alignment:
MAXIMUM_MATCHES="50"
CULLING="5"

	################################################################################
	# BLAST CLUSTERS
	################################################################################
	echo $(date +%H:%M) "BLASTing..."
	blast_output="/Users/mgb/Documents/APhD/eDNA_extra_docs/MARES/MARES_reformated_20210723.txt"
blastn \
		-query "/Users/mgb/Documents/APhD/eDNA_extra_docs/MARES/hash_key.fasta" \
		-db "${BLAST_DB}" \
		-num_threads 4 \
		-perc_identity "${PERCENT_IDENTITY}" \
		-word_size "${WORD_SIZE}" \
		-evalue "${EVALUE}" \
		-max_target_seqs "${MAXIMUM_MATCHES}" \
		-culling_limit="${CULLING}" \
		-outfmt "6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore staxids qlen" \
		-out "${blast_output}"
```

```{r}
library(insect)
library(tidyverse)
library(taxonomizr)
```


2. Using the results from Blast we add headers to the dataframe
```{r}
blast <- read_delim(("/Users/erdag/NextGenNEPA_local/classifiers/COI_build/runs1_2_3_coi_hash_key_format6.txt"), col_names = c("qseqid", "sseqid", "pident", "length", "mismatch", "gapopen", "qstart", "qend", "sstart", "send", "evalue", "bitscore", "staxid", "qlen"), delim = "\t" )

blast %>% mutate (Ntaxid = as.numeric (staxid)) %>% filter(is.na(Ntaxid))
```

so there are a number of hashes that have more than 1 taxID which are not being properly handled. To deal with this, we can try a couple things, first could try creating a table of just these ones that we can run separately after making decisions on which TaxID to take. 

```{r}
multi_tax <- blast %>% mutate (Ntaxid = as.numeric (staxid)) %>% filter(is.na(Ntaxid))
#there are 888 entries that have multiple taxIDs per hash
nblast<- blast %>% mutate (taxid = as.numeric (staxid))
```



3.pull the taxonomy using insect 
```{r}
insect::taxonomy() -> worlds.taxonomy
```

4. combine the taxonomy with the blast results
```{r}
blast %>% distinct(staxid) %>%
  pull()-> all.taxids
all.taxids <- map(all.taxids, as.numeric)
insect::get_lineage(all.taxids, worlds.taxonomy) -> all.taxonomy   
```



5. make a dataframe with all the ranks for each taxID
```{r}
Conversion.df <- tibble (taxid = all.taxids,
                         taxonomy = all.taxonomy) %>%
  mutate (Kingdom = map_chr(taxonomy, ~.x["kingdom"]),
          Phylum = map_chr(taxonomy, ~.x["phylum"]),
          Class = map_chr(taxonomy, ~.x["class"]),
          Order = map_chr(taxonomy, ~.x["order"]),
          Family= map_chr(taxonomy, ~.x["family"]),
          Genus = map_chr(taxonomy, ~.x["genus"]),
          Species = map_chr(taxonomy, ~.x["species"]))

Conversion.df %>% filter(is.na(taxid))
```

6. merge the Conversion.df with the blast df to run the consensus script
```{r}
blast.tax <- merge(nblast, Conversion.df, by= "taxid")
```



7. Create the function to find consensus
```{r}
custom.lca <- function (df, cutoff = 90) {df %>%  # this function allows to change cutoff parameters for a specified dataframe (df)
  group_by(qseqid) %>%
  select( pident, Kingdom, Phylum, Class, Order, Family, Genus, Species) %>%
  nest() %>% # for each query, calculate the agreed taxonomy
  # ungroup %>% slice (1:10) %>%
  mutate(consensus = purrr::map(data,  function(.x) { 
    # If there are 100% matches - keep those and the 90s
    # If not, keep everything
    
    if(max(.x$pident > cutoff )){
      
      .x %>% 
        filter(pident > cutoff) %>% 
        select(-pident) %>% 
        condenseTaxa() %>% # agreement in Phylogeny
      paste(., collapse = "%") # Collapse all the taxa data separatated by %
      
    }else{
    .x %>% 
        select(-pident) %>% 
    condenseTaxa() %>%
      paste(., collapse = "%")}
  }
                               )) %>%
  select(qseqid, consensus) %>%
  unnest(consensus)} 
```


8.make a dataframe with the consensus for each hash
```{r}
consensus.df <- custom.lca(blast.tax)
```
OKay so that reduced the data set down to just an assignment and the hash, but we need to keep the rest of the data in that and get it into a dataframe with all the ranks next.
